2021-09-10 18:24:38,875 - INFO: Model: "interp_cond_autoregressive_rnn"
2021-09-10 18:24:38,875 - INFO: _________________________________________________________________
2021-09-10 18:24:38,875 - INFO: Layer (type)                 Output Shape              Param #   
2021-09-10 18:24:38,875 - INFO: =================================================================
2021-09-10 18:24:38,876 - INFO: gru (GRU)                    multiple                  150528    
2021-09-10 18:24:38,876 - INFO: _________________________________________________________________
2021-09-10 18:24:38,876 - INFO: gru_1 (GRU)                  multiple                  99072     
2021-09-10 18:24:38,876 - INFO: _________________________________________________________________
2021-09-10 18:24:38,876 - INFO: bidirectional (Bidirectional multiple                  247296    
2021-09-10 18:24:38,876 - INFO: _________________________________________________________________
2021-09-10 18:24:38,877 - INFO: lang_model_output_layer (Lan multiple                  34310     
2021-09-10 18:24:38,877 - INFO: _________________________________________________________________
2021-09-10 18:24:38,877 - INFO: normalize (Normalize)        multiple                  256       
2021-09-10 18:24:38,877 - INFO: _________________________________________________________________
2021-09-10 18:24:38,877 - INFO: embedding (Embedding)        multiple                  8192      
2021-09-10 18:24:38,877 - INFO: _________________________________________________________________
2021-09-10 18:24:38,877 - INFO: dense_3 (Dense)              multiple                  128       
2021-09-10 18:24:38,877 - INFO: _________________________________________________________________
2021-09-10 18:24:38,877 - INFO: embedding_1 (Embedding)      multiple                  1280      
2021-09-10 18:24:38,878 - INFO: =================================================================
2021-09-10 18:24:38,878 - INFO: Total params: 541,062
2021-09-10 18:24:38,879 - INFO: Trainable params: 541,062
2021-09-10 18:24:38,879 - INFO: Non-trainable params: 0
2021-09-10 18:24:38,879 - INFO: _________________________________________________________________
2021-09-10 18:24:57,554 - INFO: |    100 steps | lr 9.99e-05 | ms/batch 161.19 | loss: 0.1557
2021-09-10 18:25:12,132 - INFO: |    200 steps | lr 9.98e-05 | ms/batch 145.76 | loss: 0.1085
2021-09-10 18:25:26,356 - INFO: |    300 steps | lr 9.97e-05 | ms/batch 142.23 | loss: 0.0895
2021-09-10 18:25:40,968 - INFO: |    400 steps | lr 9.96e-05 | ms/batch 146.11 | loss: 0.0745
2021-09-10 18:25:55,393 - INFO: |    500 steps | lr 9.95e-05 | ms/batch 144.23 | loss: 0.0638
2021-09-10 18:26:04,882 - INFO: eval: | step    500 | eval time: 9.479 | loss: 0.0173 | mse: 0.0167
2021-09-10 18:26:19,304 - INFO: |    600 steps | lr 9.94e-05 | ms/batch 239.10 | loss: 0.0563
2021-09-10 18:26:33,629 - INFO: |    700 steps | lr 9.93e-05 | ms/batch 143.24 | loss: 0.0506
2021-09-10 18:26:48,002 - INFO: |    800 steps | lr 9.92e-05 | ms/batch 143.72 | loss: 0.0463
2021-09-10 18:27:02,391 - INFO: |    900 steps | lr 9.91e-05 | ms/batch 143.88 | loss: 0.0428
2021-09-10 18:27:16,604 - INFO: |   1000 steps | lr 9.90e-05 | ms/batch 142.11 | loss: 0.0399
2021-09-10 18:27:25,759 - INFO: eval: | step   1000 | eval time: 9.145 | loss: 0.0155 | mse: 0.0154
2021-09-10 18:27:40,126 - INFO: |   1100 steps | lr 9.89e-05 | ms/batch 235.20 | loss: 0.0376
2021-09-10 18:27:54,653 - INFO: |   1200 steps | lr 9.88e-05 | ms/batch 145.26 | loss: 0.0356
2021-09-10 18:28:08,883 - INFO: |   1300 steps | lr 9.87e-05 | ms/batch 142.29 | loss: 0.0339
2021-09-10 18:28:23,203 - INFO: |   1400 steps | lr 9.86e-05 | ms/batch 143.19 | loss: 0.0325
2021-09-10 18:28:37,416 - INFO: |   1500 steps | lr 9.85e-05 | ms/batch 142.12 | loss: 0.0312
2021-09-10 18:28:46,831 - INFO: eval: | step   1500 | eval time: 9.405 | loss: 0.0150 | mse: 0.0149
2021-09-10 18:29:01,086 - INFO: |   1600 steps | lr 9.84e-05 | ms/batch 236.68 | loss: 0.0301
2021-09-10 18:29:15,556 - INFO: |   1700 steps | lr 9.83e-05 | ms/batch 144.70 | loss: 0.0291
2021-09-10 18:29:29,914 - INFO: |   1800 steps | lr 9.82e-05 | ms/batch 143.57 | loss: 0.0282
2021-09-10 18:29:44,156 - INFO: |   1900 steps | lr 9.81e-05 | ms/batch 142.41 | loss: 0.0273
2021-09-10 18:29:58,283 - INFO: |   2000 steps | lr 9.80e-05 | ms/batch 141.25 | loss: 0.0266
2021-09-10 18:30:07,741 - INFO: eval: | step   2000 | eval time: 9.448 | loss: 0.0149 | mse: 0.0148
2021-09-10 18:30:22,033 - INFO: |   2100 steps | lr 9.79e-05 | ms/batch 237.49 | loss: 0.0260
2021-09-10 18:30:36,316 - INFO: |   2200 steps | lr 9.78e-05 | ms/batch 142.82 | loss: 0.0253
2021-09-10 18:30:50,598 - INFO: |   2300 steps | lr 9.77e-05 | ms/batch 142.81 | loss: 0.0248
2021-09-10 18:31:05,052 - INFO: |   2400 steps | lr 9.76e-05 | ms/batch 144.53 | loss: 0.0243
2021-09-10 18:31:19,253 - INFO: |   2500 steps | lr 9.75e-05 | ms/batch 142.00 | loss: 0.0238
2021-09-10 18:31:28,755 - INFO: eval: | step   2500 | eval time: 9.491 | loss: 0.0148 | mse: 0.0148
2021-09-10 18:31:43,194 - INFO: |   2600 steps | lr 9.74e-05 | ms/batch 239.39 | loss: 0.0233
2021-09-10 18:31:57,422 - INFO: |   2700 steps | lr 9.73e-05 | ms/batch 142.27 | loss: 0.0229
2021-09-10 18:32:11,826 - INFO: |   2800 steps | lr 9.72e-05 | ms/batch 144.03 | loss: 0.0225
2021-09-10 18:32:26,026 - INFO: |   2900 steps | lr 9.71e-05 | ms/batch 141.99 | loss: 0.0222
2021-09-10 18:32:40,252 - INFO: |   3000 steps | lr 9.70e-05 | ms/batch 142.25 | loss: 0.0218
2021-09-10 18:32:50,083 - INFO: eval: | step   3000 | eval time: 9.821 | loss: 0.0147 | mse: 0.0147
2021-09-10 18:33:04,345 - INFO: |   3100 steps | lr 9.69e-05 | ms/batch 240.92 | loss: 0.0215
2021-09-10 18:33:18,801 - INFO: |   3200 steps | lr 9.68e-05 | ms/batch 144.55 | loss: 0.0212
2021-09-10 18:33:33,073 - INFO: |   3300 steps | lr 9.67e-05 | ms/batch 142.70 | loss: 0.0209
2021-09-10 18:33:47,440 - INFO: |   3400 steps | lr 9.66e-05 | ms/batch 143.66 | loss: 0.0206
2021-09-10 18:34:01,632 - INFO: |   3500 steps | lr 9.65e-05 | ms/batch 141.91 | loss: 0.0204
2021-09-10 18:34:11,097 - INFO: eval: | step   3500 | eval time: 9.455 | loss: 0.0144 | mse: 0.0144
2021-09-10 18:34:25,198 - INFO: |   3600 steps | lr 9.64e-05 | ms/batch 235.65 | loss: 0.0201
2021-09-10 18:34:39,691 - INFO: |   3700 steps | lr 9.63e-05 | ms/batch 144.92 | loss: 0.0199
2021-09-10 18:34:53,890 - INFO: |   3800 steps | lr 9.63e-05 | ms/batch 141.98 | loss: 0.0197
2021-09-10 18:35:08,285 - INFO: |   3900 steps | lr 9.62e-05 | ms/batch 143.93 | loss: 0.0195
2021-09-10 18:35:22,534 - INFO: |   4000 steps | lr 9.61e-05 | ms/batch 142.48 | loss: 0.0192
2021-09-10 18:35:32,070 - INFO: eval: | step   4000 | eval time: 9.526 | loss: 0.0148 | mse: 0.0148
2021-09-10 18:35:46,420 - INFO: |   4100 steps | lr 9.60e-05 | ms/batch 238.84 | loss: 0.0190
2021-09-10 18:36:00,851 - INFO: |   4200 steps | lr 9.59e-05 | ms/batch 144.30 | loss: 0.0189
2021-09-10 18:36:14,969 - INFO: |   4300 steps | lr 9.58e-05 | ms/batch 141.17 | loss: 0.0187
2021-09-10 18:36:29,282 - INFO: |   4400 steps | lr 9.57e-05 | ms/batch 143.11 | loss: 0.0185
2021-09-10 18:36:43,575 - INFO: |   4500 steps | lr 9.56e-05 | ms/batch 142.92 | loss: 0.0183
2021-09-10 18:36:53,145 - INFO: eval: | step   4500 | eval time: 9.560 | loss: 0.0147 | mse: 0.0146
2021-09-10 18:37:07,488 - INFO: |   4600 steps | lr 9.55e-05 | ms/batch 239.13 | loss: 0.0182
2021-09-10 18:37:21,801 - INFO: |   4700 steps | lr 9.54e-05 | ms/batch 143.12 | loss: 0.0180
2021-09-10 18:37:35,971 - INFO: |   4800 steps | lr 9.53e-05 | ms/batch 141.68 | loss: 0.0179
2021-09-10 18:37:50,488 - INFO: |   4900 steps | lr 9.52e-05 | ms/batch 145.16 | loss: 0.0177
2021-09-10 18:38:04,605 - INFO: |   5000 steps | lr 9.51e-05 | ms/batch 141.16 | loss: 0.0176
2021-09-10 18:38:13,877 - INFO: eval: | step   5000 | eval time: 9.262 | loss: 0.0143 | mse: 0.0143
2021-09-10 18:38:28,199 - INFO: |   5100 steps | lr 9.50e-05 | ms/batch 235.93 | loss: 0.0174
2021-09-10 18:38:42,585 - INFO: |   5200 steps | lr 9.49e-05 | ms/batch 143.85 | loss: 0.0173
2021-09-10 18:38:56,838 - INFO: |   5300 steps | lr 9.48e-05 | ms/batch 142.51 | loss: 0.0172
2021-09-10 18:39:10,973 - INFO: |   5400 steps | lr 9.47e-05 | ms/batch 141.35 | loss: 0.0170
2021-09-10 18:39:26,927 - INFO: |   5500 steps | lr 9.46e-05 | ms/batch 159.52 | loss: 0.0169
2021-09-10 18:39:36,690 - INFO: eval: | step   5500 | eval time: 9.751 | loss: 0.0147 | mse: 0.0147
2021-09-10 18:39:51,371 - INFO: |   5600 steps | lr 9.45e-05 | ms/batch 244.43 | loss: 0.0168
2021-09-10 18:40:05,867 - INFO: |   5700 steps | lr 9.44e-05 | ms/batch 144.95 | loss: 0.0167
2021-09-10 18:40:20,528 - INFO: |   5800 steps | lr 9.43e-05 | ms/batch 146.59 | loss: 0.0166
2021-09-10 18:40:35,146 - INFO: |   5900 steps | lr 9.42e-05 | ms/batch 146.17 | loss: 0.0165
2021-09-10 18:40:49,904 - INFO: |   6000 steps | lr 9.41e-05 | ms/batch 147.57 | loss: 0.0164
2021-09-10 18:40:59,716 - INFO: eval: | step   6000 | eval time: 9.802 | loss: 0.0148 | mse: 0.0147
2021-09-10 18:41:14,194 - INFO: |   6100 steps | lr 9.41e-05 | ms/batch 242.88 | loss: 0.0163
2021-09-10 18:41:28,795 - INFO: |   6200 steps | lr 9.40e-05 | ms/batch 145.99 | loss: 0.0162
2021-09-10 18:41:43,587 - INFO: |   6300 steps | lr 9.39e-05 | ms/batch 147.90 | loss: 0.0161
2021-09-10 18:41:58,075 - INFO: |   6400 steps | lr 9.38e-05 | ms/batch 144.87 | loss: 0.0160
2021-09-10 18:42:12,717 - INFO: |   6500 steps | lr 9.37e-05 | ms/batch 146.41 | loss: 0.0159
2021-09-10 18:42:22,430 - INFO: eval: | step   6500 | eval time: 9.703 | loss: 0.0155 | mse: 0.0155
2021-09-10 18:42:37,115 - INFO: |   6600 steps | lr 9.36e-05 | ms/batch 243.96 | loss: 0.0158
2021-09-10 18:42:51,568 - INFO: |   6700 steps | lr 9.35e-05 | ms/batch 144.52 | loss: 0.0157
2021-09-10 18:43:06,138 - INFO: |   6800 steps | lr 9.34e-05 | ms/batch 145.69 | loss: 0.0156
2021-09-10 18:43:20,712 - INFO: |   6900 steps | lr 9.33e-05 | ms/batch 145.72 | loss: 0.0155
2021-09-10 18:43:35,504 - INFO: |   7000 steps | lr 9.32e-05 | ms/batch 147.91 | loss: 0.0154
2021-09-10 18:43:45,197 - INFO: eval: | step   7000 | eval time: 9.684 | loss: 0.0151 | mse: 0.0150
2021-09-10 18:43:59,524 - INFO: |   7100 steps | lr 9.31e-05 | ms/batch 240.19 | loss: 0.0154
2021-09-10 18:44:14,059 - INFO: |   7200 steps | lr 9.30e-05 | ms/batch 145.33 | loss: 0.0153
2021-09-10 18:44:28,381 - INFO: |   7300 steps | lr 9.29e-05 | ms/batch 143.21 | loss: 0.0152
2021-09-10 18:44:42,670 - INFO: |   7400 steps | lr 9.28e-05 | ms/batch 142.87 | loss: 0.0151
2021-09-10 18:44:56,935 - INFO: |   7500 steps | lr 9.27e-05 | ms/batch 142.64 | loss: 0.0150
2021-09-10 18:45:06,389 - INFO: eval: | step   7500 | eval time: 9.443 | loss: 0.0148 | mse: 0.0148
